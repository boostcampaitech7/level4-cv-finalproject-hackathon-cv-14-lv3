from fastapi import FastAPI, WebSocket, WebSocketDisconnect,HTTPException
from fastapi.middleware.cors import CORSMiddleware
import httpx
from datetime import datetime
import pandas as pd
import sqlalchemy
import re
from dotenv import load_dotenv
import os
import requests
import json
from openai import OpenAI
from supabase import create_client
from supabase.lib.client_options import ClientOptions
import time
import sqlite3
from pydantic import BaseModel
from typing import List

# 1) FastAPI ì•± ìƒì„±
app = FastAPI()

# WebSocket ì—°ê²° ê´€ë¦¬ 
active_connections = []

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
UPSTAGE_API_KEY = os.getenv('UPSTAGE_API_KEY')
UPSTAGE_API_BASE_URL = os.getenv('UPSTAGE_API_BASE_URL')
SUPABASE_URL = os.getenv('SUPABASE_URL')
SUPABASE_KEY = os.getenv('SUPABASE_KEY')

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
options = ClientOptions(postgrest_client_timeout=600)  # íƒ€ì„ì•„ì›ƒì„ 600ì´ˆë¡œ ì„¤ì •
supabase = create_client(SUPABASE_URL, SUPABASE_KEY, options)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(
    api_key=UPSTAGE_API_KEY,
    base_url=UPSTAGE_API_BASE_URL
)

# ===== ë°ì´í„° ë¡œë”© =====
# Supabase ì—°ê²° ì¬ì„¤ì • í•¨ìˆ˜
def reconnect_supabase():
    global supabase
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
    print("Reconnected to Supabase.")

# Supabaseì—ì„œ ëª¨ë“  ë ˆì½”ë“œë¥¼ í˜ì´ì§€ë„¤ì´ì…˜(Chunk) ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ê³µí†µ í•¨ìˆ˜
def load_all_data(table_name):
    all_data = []
    chunk_size = 100000
    start = 0

    while True:
        response = (
            supabase
            .table(table_name)
            .select("*")
            .range(start, start + chunk_size - 1)
            .execute()
        )
        fetched_data = response.data

        # ê° ì‚¬ì´í´ì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ê°œìˆ˜ ì¶œë ¥
        print(f"Fetched {len(fetched_data)} rows from {table_name} (range: {start}~{start + chunk_size - 1})")

        if not fetched_data:
            # ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            break

        all_data.extend(fetched_data)
        start += chunk_size

    return all_data

# daily_sales_data í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì½ì–´ì™€ DataFrameìœ¼ë¡œ ë³€í™˜
def load_sales_data():
    all_data = load_all_data("daily_sales_data")
    df = pd.DataFrame(all_data)

    # date ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ë©´ datetimeìœ¼ë¡œ ë³€í™˜
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    return df

# daily_data í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì½ì–´ì™€ DataFrameìœ¼ë¡œ ë³€í™˜
def load_quantity_data():
    all_data = load_all_data("daily_data")
    df = pd.DataFrame(all_data)
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
    return df

# product_inventory í…Œì´ë¸”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ ì½ì–´ì™€ DataFrameìœ¼ë¡œ ë³€í™˜
def load_inventory_data():
    all_data = load_all_data("product_inventory")
    df = pd.DataFrame(all_data)
    return df


# ë°ì´í„° ë¡œë“œ
df_sales = load_sales_data()
reconnect_supabase()
inventory_df = load_inventory_data()
reconnect_supabase()
df_quantity = load_quantity_data()


# ===== ì»¬ëŸ¼ëª… ë³€ê²½ =====
df_sales = df_sales.rename(columns={'value': 'ë§¤ì¶œì•¡'})
df_quantity = df_quantity.rename(columns={'value': 'íŒë§¤ìˆ˜ëŸ‰'})
inventory_df = inventory_df.rename(columns={'value': 'ì¬ê³ ìˆ˜ëŸ‰'})

# ë¬¸ìì—´ ë³€í™˜
df_sales['date'] = df_sales['date'].astype(str)
df_quantity['date'] = df_quantity['date'].astype(str)

# ë§Œì•½ df_salesì— 'ëŒ€ë¶„ë¥˜' í˜¹ì€ 'ì†Œë¶„ë¥˜' ì»¬ëŸ¼ì´ ì—†ë‹¤ë©´ product_info ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ë³‘í•©
if 'ì†Œë¶„ë¥˜' not in df_sales.columns or 'ëŒ€ë¶„ë¥˜' not in df_sales.columns:
    # product_info í…Œì´ë¸”ì—ëŠ” id, main, sub1, sub2, sub3ê°€ ìˆìŒ (ì—¬ê¸°ì„œëŠ” sub1: ëŒ€ë¶„ë¥˜, sub3: ì†Œë¶„ë¥˜ë¡œ ì‚¬ìš©)
    product_info_response = supabase.from_('product_info').select("id, sub1, sub3").execute()
    df_product_info = pd.DataFrame(product_info_response.data)
    # í•„ìš”í•œ ì»¬ëŸ¼ëª…ì„ ë³€ê²½í•©ë‹ˆë‹¤.
    df_product_info = df_product_info.rename(columns={"sub1": "ëŒ€ë¶„ë¥˜", "sub3": "ì†Œë¶„ë¥˜"})
    # df_salesì— product_infoë¥¼ idë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•© (left join)
    df_sales = df_sales.merge(df_product_info[["id", "ëŒ€ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]], on="id", how="left")

# ===== Dash ì½”ë“œì—ì„œ í•˜ë˜ ì „ì²˜ë¦¬ ë¡œì§ =====

data = df_sales.copy()
data_quantity = df_quantity.copy()

data['ë‚ ì§œ'] = pd.to_datetime(data['date'])
data_quantity['ë‚ ì§œ'] = pd.to_datetime(data_quantity['date'])

# ì¼ê°„ í•©ê³„
daily_df = data.groupby('ë‚ ì§œ', as_index=False)['ë§¤ì¶œì•¡'].sum()
daily_df = daily_df.rename(columns={'ë§¤ì¶œì•¡': 'ê°’'})

# ì£¼ê°„ ì§‘ê³„ (ë‚ ì§œë¥¼ ì£¼ ì‹œì‘ì¼ë¡œ ë³€í™˜í•˜ì—¬ ê·¸ë£¹í™”)
daily_df['ì£¼ê°„'] = daily_df['ë‚ ì§œ'].dt.to_period('W').apply(lambda r: r.start_time)
weekly_data = daily_df.groupby('ì£¼ê°„', as_index=False)['ê°’'].sum()

# ì›”ê°„ ì§‘ê³„ (ë‚ ì§œë¥¼ ì›” ì‹œì‘ì¼ë¡œ ë³€í™˜í•˜ì—¬ ê·¸ë£¹í™”)
daily_df['ì›”ê°„'] = daily_df['ë‚ ì§œ'].dt.to_period('M').apply(lambda r: r.start_time)
monthly_sum_df = daily_df.groupby('ì›”ê°„', as_index=False)['ê°’'].sum()

# ìµœê·¼ 12ê°œì›” í•©ê³„ë¥¼ "ì—°ê°„ ë§¤ì¶œ"ë¡œ ê°€ì •
recent_12_months = monthly_sum_df.tail(12)
annual_sales = recent_12_months['ê°’'].sum()

# KPI ê³„ì‚°
daily_avg = daily_df['ê°’'].mean() if not daily_df.empty else 0
weekly_avg = weekly_data['ê°’'].mean() if not weekly_data.empty else 0
monthly_avg = monthly_sum_df['ê°’'].mean() if not monthly_sum_df.empty else 0
last_daily = daily_df['ê°’'].iloc[-1] if not daily_df.empty else 0
last_weekly = weekly_data['ê°’'].iloc[-1] if not weekly_data.empty else 0
last_monthly = monthly_sum_df['ê°’'].iloc[-1] if not monthly_sum_df.empty else 0

# ì›”ê°„ ë³€í™”ìœ¨ ê³„ì‚°
if len(monthly_sum_df) >= 2:
    lm_sales = monthly_sum_df['ê°’'].iloc[-1]
    slm_sales = monthly_sum_df['ê°’'].iloc[-2]
    monthly_change = ((lm_sales - slm_sales) / slm_sales) * 100 if slm_sales != 0 else 0
else:
    monthly_change = 0

# ì¹´í…Œê³ ë¦¬ë³„(ëŒ€ë¶„ë¥˜) ë§¤ì¶œ
df_category = df_sales.groupby('ëŒ€ë¶„ë¥˜', as_index=False)['ë§¤ì¶œì•¡'].sum()

# ì¬ê³ ìˆ˜ëŸ‰ ë° ì¼ì¼íŒë§¤ìˆ˜ëŸ‰ ì²˜ë¦¬
data_quantity['ë‚ ì§œ'] = pd.to_datetime(data_quantity['date'])
last_date = data_quantity['ë‚ ì§œ'].max()
if last_date:
    daily_sales_quantity_last = data_quantity[data_quantity['ë‚ ì§œ'] == last_date][['id', 'íŒë§¤ìˆ˜ëŸ‰']]
    daily_sales_quantity_last = daily_sales_quantity_last.rename(columns={'íŒë§¤ìˆ˜ëŸ‰': 'ì¼íŒë§¤ìˆ˜ëŸ‰'})
else:
    daily_sales_quantity_last = pd.DataFrame(columns=['id', 'ì¼íŒë§¤ìˆ˜ëŸ‰'])

merged_df = pd.merge(inventory_df, daily_sales_quantity_last, on='id', how='left')
merged_df['ì¼íŒë§¤ìˆ˜ëŸ‰'] = merged_df['ì¼íŒë§¤ìˆ˜ëŸ‰'].fillna(0)
merged_df['ë‚¨ì€ ì¬ê³ '] = merged_df['ì¬ê³ ìˆ˜ëŸ‰'] - merged_df['ì¼íŒë§¤ìˆ˜ëŸ‰']
low_stock_df = merged_df[(merged_df['ë‚¨ì€ ì¬ê³ '] >= 0) & (merged_df['ë‚¨ì€ ì¬ê³ '] <= 30)]

# ë§¤ì¶œ ìƒìŠ¹í­(ì†Œë¶„ë¥˜)
# ë§Œì•½ ì†Œë¶„ë¥˜ ê°’ì´ ì—†ëŠ” ê²½ìš° "ê¸°íƒ€" ì²˜ë¦¬
data["ì†Œë¶„ë¥˜"] = data["ì†Œë¶„ë¥˜"].fillna('ê¸°íƒ€')
pivot_subcat = data.groupby(['ì†Œë¶„ë¥˜', 'ë‚ ì§œ'])['ë§¤ì¶œì•¡'].sum().unstack().fillna(0)
all_dates = sorted(pivot_subcat.columns)
if len(all_dates) >= 2:
    last_date_val, second_last_date_val = all_dates[-1], all_dates[-2]
    last_sum = pivot_subcat[last_date_val].sum()
    second_sum = pivot_subcat[second_last_date_val].sum()
    rise_rate = ((last_sum - second_sum) / second_sum) * 100 if second_sum != 0 else 0
else:
    rise_rate = 0

subcat_list = pivot_subcat.sum(axis=1).sort_values(ascending=False).head(10).index.tolist()

# ---------- (ì¶”ê°€) ìƒ/í•˜ìœ„ 10ê°œ ê³„ì‚° ----------
monthly_data = (
    data.assign(ì›”=lambda df: df['ë‚ ì§œ'].dt.to_period('M').astype(str))
    .groupby(['id', 'ì›”'], as_index=False)['ë§¤ì¶œì•¡'].sum()
)
result = monthly_data.pivot(index='id', columns='ì›”', values='ë§¤ì¶œì•¡').reset_index()
result['id'] = result['id'].astype(str)
if len(result.columns) > 1:
    last_month_col = result.columns[-1]
else:
    last_month_col = None

reds = ['#D14B4B', '#E22B2B', '#E53A3A', '#F15D5D', '#F67878',
        '#F99A9A', '#FBB6B6', '#FDC8C8', '#FEE0E0', '#FEEAEA']
blues = ['#B0D6F1', '#A5C9E9', '#99BCE1', '#8DB0D9', '#81A4D1',
         '#7498C9', '#688BC1', '#5C7FB9', '#5073B1', '#4567A9']

# ===== ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

@app.get("/")
def read_root():
    return {
        "status": "success",
    }

@app.get("/api/kpis")
def get_kpis():
    # ë„˜íŒŒì´ ì •ìˆ˜/ì‹¤ìˆ˜ -> íŒŒì´ì¬ int/float
    return {
        "annual_sales": int(annual_sales),
        "daily_avg": float(daily_avg),
        "weekly_avg": float(weekly_avg),
        "monthly_avg": float(monthly_avg),
        "last_daily": int(last_daily),
        "last_weekly": int(last_weekly),
        "last_monthly": int(last_monthly),
        "monthly_change": float(monthly_change),
    }

@app.get("/api/daily")
def get_daily_data():
    # 2023ë…„ ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
    filtered_daily = daily_df
    return filtered_daily.to_dict(orient="records")

@app.get("/api/weekly")
def get_weekly_data():
    # 2022ë…„ 10ì›” ì´í›„ ë°ì´í„°ë§Œ í•„í„°ë§
    filtered_weekly = weekly_data
    return filtered_weekly.to_dict(orient="records")

@app.get("/api/monthly")
def get_monthly_data():
    return monthly_sum_df.to_dict(orient="records")

@app.get("/api/categorypie")
def get_category_pie():
    # ë§¤ì¶œì•¡ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ 5ê°œë§Œ ì„ íƒ
    top_5_categories = df_category.nlargest(5, 'ë§¤ì¶œì•¡')
    return top_5_categories.to_dict(orient="records")

@app.get("/api/lowstock")
def get_low_stock():
    # merged_dfì™€ low_stock_dfê°€ ì „ì—­ ë³€ìˆ˜ë¡œ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    global merged_df, low_stock_df

    try:
        # product_info í…Œì´ë¸”ì—ì„œ sub3 ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        response = supabase.table('product_info').select("id", "sub3").execute()
        product_info = pd.DataFrame(response.data)
        product_info = product_info.rename(columns={'id': 'id', 'sub3': 'Sub3'})

        # low_stock_dfì™€ product_info ë³‘í•©
        merged_low_stock = pd.merge(low_stock_df, product_info, on='id', how='left')

        return merged_low_stock.to_dict(orient="records")
    except Exception as e:
        print(f"Error in get_low_stock: {e!s}")
        return {"error": str(e)}

@app.get("/api/rising-subcategories")
def get_rising_subcategories():
    return {
        "rise_rate": float(rise_rate),
        "subcat_list": list(subcat_list)  # ë„˜íŒŒì´ Index -> list
    }

# (ì¶”ê°€) ìƒÂ·í•˜ìœ„ 10ê°œ í’ˆëª©
@app.get("/api/topbottom")
def get_topbottom():
    if last_month_col:
        # Supabaseì—ì„œ product_info ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        response = supabase.table('product_info').select("id", "sub3").execute()
        product_info = pd.DataFrame(response.data)

        # ID ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        product_info['id'] = product_info['id'].astype(str)
        product_info = product_info.rename(columns={'id': 'ID', 'sub3': 'Sub3'})

        # top 10
        top_10_df = result.nlargest(10, last_month_col, keep='all').copy()
        top_10_df = top_10_df.rename(columns={'id': 'ID'})
        top_10_df['ID'] = top_10_df['ID'].astype(str)
        top_10_df = pd.merge(top_10_df, product_info, on='ID', how='left')
        top_10_list = top_10_df.to_dict('records')  # DataFrameì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

        # bottom 10
        non_zero_values = result[result[last_month_col] != 0]
        bottom_10_df = non_zero_values.nsmallest(10, last_month_col).copy()
        bottom_10_df = bottom_10_df.rename(columns={'id': 'ID'})
        bottom_10_df['ID'] = bottom_10_df['ID'].astype(str)
        bottom_10_df = pd.merge(bottom_10_df, product_info, on='ID', how='left')
        bottom_10_list = bottom_10_df.to_dict('records')  # DataFrameì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    else:
        top_10_list = []
        bottom_10_list = []

    return {
        "top_10": top_10_list,
        "bottom_10": bottom_10_list,
        "last_month_col": last_month_col
    }

# ì±—ë´‡ìš© ë°ì´í„° ë¯¸ë¦¬ ì¤€ë¹„
def prepare_chat_data():
    # ì›”ë³„ ë§¤ì¶œ ë°ì´í„°
    monthly_sales_text = "ì›”ë³„ ë§¤ì¶œ ë°ì´í„°:\n" + "\n".join([
        f"{row['ì›”ê°„'].strftime('%Y-%m')}: {row['ê°’']:,}ì›"
        for row in monthly_sum_df.to_dict('records')
    ])

    # ì£¼ê°„ ë§¤ì¶œ ë°ì´í„°
    weekly_sales_text = "ì£¼ê°„ ë§¤ì¶œ ë°ì´í„°:\n" + "\n".join([
        f"{row['ì£¼ê°„'].strftime('%Y-%m-%d')}: {row['ê°’']:,}ì›"
        for row in weekly_data.tail(12).to_dict('records')
    ])

    # ì¼ë³„ ë§¤ì¶œ ë°ì´í„°
    daily_sales_text = "ìµœê·¼ 30ì¼ ì¼ë³„ ë§¤ì¶œ ë°ì´í„°:\n" + "\n".join([
        f"{row['ë‚ ì§œ'].strftime('%Y-%m-%d')}: {row['ê°’']:,}ì›"
        for row in daily_df.tail(30).to_dict('records')
    ])

    # ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ìƒì„¸
    category_details = df_sales.groupby('ëŒ€ë¶„ë¥˜').agg({
        'ë§¤ì¶œì•¡': ['sum', 'mean', 'count']
    }).reset_index()
    category_details.columns = ['ëŒ€ë¶„ë¥˜', 'ì´ë§¤ì¶œ', 'í‰ê· ë§¤ì¶œ', 'íŒë§¤ê±´ìˆ˜']

    category_text = "ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ìƒì„¸:\n" + "\n".join([
        f"{row['ëŒ€ë¶„ë¥˜']}: ì´ë§¤ì¶œ {row['ì´ë§¤ì¶œ']:,}ì›, í‰ê·  {row['í‰ê· ë§¤ì¶œ']:,.0f}ì›, {row['íŒë§¤ê±´ìˆ˜']}ê±´"
        for _, row in category_details.iterrows()
    ])

    # ì¬ê³  í˜„í™© ìƒì„¸
    inventory_status = pd.merge(
        inventory_df,
        daily_sales_quantity_last,
        on='id',
        how='left'
    )

    # product_info í…Œì´ë¸”ì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    product_info_response = supabase.from_('product_info').select("id,main,sub3").execute()
    product_info_df = pd.DataFrame(product_info_response.data)

    # ë°ì´í„° ë³‘í•©
    inventory_status = pd.merge(
        inventory_status,
        product_info_df,
        left_on='id',
        right_on='id',
        how='left'
    )

    inventory_status['ì¼íŒë§¤ìˆ˜ëŸ‰'] = inventory_status['ì¼íŒë§¤ìˆ˜ëŸ‰'].fillna(0)
    inventory_status['ë‚¨ì€ì¬ê³ '] = inventory_status['ì¬ê³ ìˆ˜ëŸ‰'] - inventory_status['ì¼íŒë§¤ìˆ˜ëŸ‰']

    inventory_text = "ì¹´í…Œê³ ë¦¬ë³„ ì¬ê³  í˜„í™©:\n" + "\n".join([
        f"{row['main'] if pd.notna(row['main']) else 'ë¯¸ë¶„ë¥˜'}({row['sub3'] if pd.notna(row['sub3']) else 'ë¯¸ë¶„ë¥˜'}): "
        f"ì´ì¬ê³  {row['ì¬ê³ ìˆ˜ëŸ‰']}ê°œ, ì¼íŒë§¤ëŸ‰ {row['ì¼íŒë§¤ìˆ˜ëŸ‰']}ê°œ, ë‚¨ì€ì¬ê³  {row['ë‚¨ì€ì¬ê³ ']}ê°œ"
        for _, row in inventory_status.iterrows()
    ])

    return {
        "monthly_sales": monthly_sales_text,
        "weekly_sales": weekly_sales_text,
        "daily_sales": daily_sales_text,
        "category_details": category_text,
        "inventory_status": inventory_text
    }

# ë°ì´í„° ë¯¸ë¦¬ ì¤€ë¹„
CHAT_DATA = prepare_chat_data()

@app.post("/api/chat")
async def chat_with_solar(message: dict):
    try:
        # product_info í…Œì´ë¸”ì—ì„œ sub3 ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        response = supabase.table('product_info').select("id, sub3").execute()
        product_info = pd.DataFrame(response.data)
        product_info = product_info.rename(columns={'id': 'id', 'sub3': 'Sub3'})

        # low_stock_dfì™€ product_info ë³‘í•©
        merged_low_stock = pd.merge(low_stock_df, product_info, on='id', how='left')
        total_low_stock = len(merged_low_stock)

        if total_low_stock > 0:
            low_stock_list = "\n".join([
                f"- {row['Sub3'] if pd.notna(row['Sub3']) else 'ë¯¸ë¶„ë¥˜'}: {row['ë‚¨ì€ ì¬ê³ ']}ê°œ"
                for _, row in merged_low_stock.iterrows()
            ])
        else:
            low_stock_list = "í˜„ì¬ ì¬ê³  ë¶€ì¡± ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤."

        system_message = f"""
        ë‹¹ì‹ ì€ íŒë§¤ ë°ì´í„° ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

        1. ë§¤ì¶œì´ë‚˜ ì¬ê³  ê´€ë ¨ ì§ˆë¬¸ì´ ëª¨í˜¸í•œ ê²½ìš°:
        - "ì–´ë–¤ ê¸°ê°„ì˜ ë§¤ì¶œì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”? ì¼ê°„, ì£¼ê°„, ì›”ê°„ ë“± êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œë©´ ìì„¸íˆ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
        - "ì–´ë–¤ ì œí’ˆì˜ ì¬ê³ ë¥¼ í™•ì¸í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”? íŠ¹ì • ì¹´í…Œê³ ë¦¬ë‚˜ ì œí’ˆì„ ë§ì”€í•´ ì£¼ì‹œë©´ ì •í™•í•œ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."

        2. ë§¤ì¶œì´ë‚˜ ì¬ê³ ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì¸ ê²½ìš°:
        - "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ë§¤ì¶œê³¼ ì¬ê³  ê´€ë ¨ ë¬¸ì˜ë§Œ ë‹µë³€ ê°€ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."

        3. ë§¤ì¶œì´ë‚˜ ì¬ê³ ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì¸ ê²½ìš°ì—ë§Œ ì•„ë˜ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:

        === ë§¤ì¶œ í˜„í™© ===
        - ì—°ê°„ ë§¤ì¶œ: {int(annual_sales):,}ì›
        - ì¼í‰ê·  ë§¤ì¶œ: {float(daily_avg):,.0f}ì›
        - ì£¼ê°„ í‰ê·  ë§¤ì¶œ: {float(weekly_avg):,.0f}ì›
        - ì›”ê°„ í‰ê·  ë§¤ì¶œ: {float(monthly_avg):,.0f}ì›
        - ìµœê·¼ ì¼ì¼ ë§¤ì¶œ: {int(last_daily):,}ì›
        - ìµœê·¼ ì£¼ê°„ ë§¤ì¶œ: {int(last_weekly):,}ì›
        - ìµœê·¼ ì›”ê°„ ë§¤ì¶œ: {int(last_monthly):,}ì›
        - ì „ì›” ëŒ€ë¹„ ë³€í™”ìœ¨: {float(monthly_change):.1f}%

        === ì¹´í…Œê³ ë¦¬ ë¶„ì„ ===
        - ë§¤ì¶œ ìƒìŠ¹ë¥ : {float(rise_rate):.1f}%
        - ì£¼ìš” ì„±ì¥ ì¹´í…Œê³ ë¦¬(ì†Œë¶„ë¥˜): {', '.join(subcat_list[:5])}

        === ì¬ê³  í˜„í™© ===
        - ì¬ê³  ë¶€ì¡± ìƒí’ˆ ìˆ˜: {total_low_stock}ê°œ
        - ì¬ê³  ë¶€ì¡± ìƒí’ˆ ëª©ë¡:
        {low_stock_list}

        ë‹µë³€ ì‹œ ì£¼ì˜ì‚¬í•­:
        1. ë§¤ì¶œ/ì¬ê³  ê´€ë ¨ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì—ë§Œ ê´€ë ¨ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€
        2. ë§¤ì¶œ/ì¬ê³  ê´€ë ¨ ëª¨í˜¸í•œ ì§ˆë¬¸ì—ëŠ” ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ìš”ì²­
        3. ë§¤ì¶œ/ì¬ê³ ì™€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì—ëŠ” ë§¤ì¶œ/ì¬ê³  ê´€ë ¨ ë¬¸ì˜ë§Œ ê°€ëŠ¥í•˜ë‹¤ê³  ì•ˆë‚´
        4. ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ì–´ì¡° ìœ ì§€
        5. ë¶ˆí•„ìš”í•œ ë°ì´í„°ëŠ” ì œì™¸í•˜ê³  ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë§Œ ì œê³µ
        6. ë‹µë³€í•  ë•Œ ë¶ˆë¦¿ í¬ì¸íŠ¸(-) ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„
        """

        response = client.chat.completions.create(
            model="solar-pro",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": message["content"]}
            ],
            temperature=0.0,
            stream=False,
            response_format={"type": "text/html"}  # HTML í˜•ì‹ ì‘ë‹µ ìš”ì²­
        )

        if hasattr(response, 'error'):
            return {
                "response": f"API ì˜¤ë¥˜: {response.error}",
                "status": "error",
                "error": str(response.error)
            }

        return {
            "response": response.choices[0].message.content,
            "status": "success"
        }

    except Exception as e:
        print(f"Error details: {e!s}")
        return {
            "response": f"ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e!s}",
            "status": "error",
            "error": str(e)
        }

@app.get("/api/trend-categories")
async def get_trend_categories():
    try:
        # ë‹¨ìˆœíˆ trending_product í…Œì´ë¸”ì—ì„œ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì¡°íšŒ
        response = supabase.table('trend_product')\
            .select('category')\
            .execute()
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        categories = sorted(list(set([item['category'] for item in response.data])))
        
        return {
            "status": "success",
            "categories": categories
        }

    except Exception as e:
        print(f"Error in trend-chat: {e!s}")
        return {
            "status": "error",
            "error": f"ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e!s}"
        }

@app.post("/api/trend-chat")
async def chat_with_trend(message: dict):
   try:
       # trend_product í…Œì´ë¸”ì—ì„œ ëª¨ë“  ë°ì´í„° ì¡°íšŒ
       response = supabase.table('trend_product')\
           .select('*')\
           .order('rank')\
           .execute()

       trend_data = response.data

       # íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬
       categorized_trends = {}
       for item in trend_data:
           category = item['category'].strip()  
           if category not in categorized_trends:
               categorized_trends[category] = []
           categorized_trends[category].append({
               'rank': item['rank'],
               'product_name': item['product_name'],
               'start_date': item['start_date'],
               'end_date': item['end_date']
           })

       # ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ì¹´í…Œê³ ë¦¬ í™•ì¸
       user_category = message["content"].strip()
       
       if user_category in categorized_trends:
           # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ìƒìœ„ 5ê°œ ìˆœìœ„ ì •ë³´ êµ¬ì„±
           trend_info = []
           category_data = sorted(categorized_trends[user_category], key=lambda x: x['rank'])[:5]
           
           # ê¸°ê°„ ì •ë³´ ì¶”ì¶œ
           period = f"{category_data[0]['start_date']} ~ {category_data[0]['end_date']}"
           
           # ìˆœìœ„ ì •ë³´ êµ¬ì„±
           for item in category_data:
               trend_info.append(f"{item['rank']}ìœ„: {item['product_name']}")
           
           trend_text = "\n".join(trend_info)
           
           # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±
           system_message = f"""
           ë‹¹ì‹ ì€ ì‡¼í•‘ íŠ¸ë Œë“œ ë¶„ì„ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
           
           ë‹¤ìŒì€ {user_category} ì¹´í…Œê³ ë¦¬ì˜ {period} ê¸°ê°„ ë™ì•ˆì˜ ì›”ê°„ íŠ¸ë Œë“œ ë°ì´í„°ì…ë‹ˆë‹¤:
           
           {trend_text}
           
           ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µí•´ì£¼ì„¸ìš”:
           1. ì¹´í…Œê³ ë¦¬ëª… ëª…ì‹œ
           2. ìƒìœ„ 5ê°œ ì œí’ˆì˜ ìˆœìœ„ì™€ ì´ë¦„ ë‚˜ì—´
           3. ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì–´ì¡° ìœ ì§€
           """

           # Solar ChatAPI ì‘ë‹µ ìƒì„±
           response = client.chat.completions.create(
               model="solar-pro",
               messages=[
                   {"role": "system", "content": system_message},
                   {"role": "user", "content": f"{user_category} ì¹´í…Œê³ ë¦¬ì˜ íŠ¸ë Œë“œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”."}
               ],
               temperature=0.0, 
               stream=False,
               response_format={"type": "text/html"}
           )

           if hasattr(response, 'error'):
               return {
                   "response": f"API ì˜¤ë¥˜: {response.error}",
                   "status": "error",
                   "error": str(response.error)
               }

           return {
               "response": response.choices[0].message.content,
               "status": "success"
           }
       else:
           # ì¹´í…Œê³ ë¦¬ê°€ ì—†ëŠ” ê²½ìš° ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜
           available_categories = list(categorized_trends.keys())
           return {
               "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. '{user_category}' ì¹´í…Œê³ ë¦¬ëŠ” í˜„ì¬ íŠ¸ë Œë“œ ì •ë³´ì— ì—†ìŠµë‹ˆë‹¤.\n\nì¡°íšŒ ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: {', '.join(available_categories)}",
               "status": "success"
           }

   except Exception as e:
       print(f"Error in trend-chat: {str(e)}")
       return {
           "status": "error",
           "error": f"ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
       }

@app.get("/api/top-sales-items")
def get_top_sales_items():
    try:
        # ì „ì—­ ë³€ìˆ˜ë¡œ ì´ë¯¸ ë¡œë“œëœ df_sales ì‚¬ìš©
        global df_sales

        # date ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
        df_sales['date'] = pd.to_datetime(df_sales['date'])

        # ìµœê·¼ 3ê°œì›” ë°ì´í„° í•„í„°ë§
        latest_date = df_sales['date'].max()
        three_months_ago = latest_date - pd.DateOffset(months=3)
        recent_data = df_sales[df_sales['date'] >= three_months_ago]

        # IDë³„ ì´ ë§¤ì¶œì•¡ ê³„ì‚° ë° ìƒìœ„ 5ê°œ ì„ íƒ
        total_sales_by_id = recent_data.groupby(['id', 'ì†Œë¶„ë¥˜'])['ë§¤ì¶œì•¡'].sum().reset_index()
        top_5 = total_sales_by_id.nlargest(5, 'ë§¤ì¶œì•¡')

        # ìµœê·¼ 2ì¼ ë‚ ì§œ êµ¬í•˜ê¸°
        prev_date = df_sales[df_sales['date'] < latest_date]['date'].max()

        result = []
        for _, row in top_5.iterrows():
            item_id = row['id']
            item_data = df_sales[df_sales['id'] == item_id]

            # ìµœê·¼ 2ì¼ ë§¤ì¶œì•¡
            latest_sales = item_data[item_data['date'] == latest_date]['ë§¤ì¶œì•¡'].sum()
            prev_sales = item_data[item_data['date'] == prev_date]['ë§¤ì¶œì•¡'].sum()

            # ì¦ê°ë¥  ê³„ì‚°
            change_rate = ((latest_sales - prev_sales) / prev_sales * 100) if prev_sales != 0 else 0

            result.append({
                "id": item_id,
                "name": row['ì†Œë¶„ë¥˜'] if pd.notna(row['ì†Œë¶„ë¥˜']) else f"Product {item_id}",
                "sales": float(latest_sales),
                "change_rate": float(change_rate)
            })

        return result if result else []
    except Exception as e:
        print(f"Error in get_top_sales_items: {str(e)}")
        return []

@app.get("/api/daily-top-sales")
def get_daily_top_sales():
    try:
        # ì´ë¯¸ ë³‘í•©ëœ df_sales ì‚¬ìš© (ëŒ€ë¶„ë¥˜, ì†Œë¶„ë¥˜ ì •ë³´ í¬í•¨)
        latest_date = df_sales['date'].max()
        latest_sales = df_sales[df_sales['date'] == latest_date].copy()
        
        # ì œí’ˆë³„ ë§¤ì¶œì•¡ í•©ê³„ ê³„ì‚° ë° ìƒìœ„ 7ê°œ ì„ íƒ
        daily_top_7 = latest_sales.groupby(['id', 'ëŒ€ë¶„ë¥˜', 'ì†Œë¶„ë¥˜'], as_index=False)['ë§¤ì¶œì•¡'].sum()
        daily_top_7 = daily_top_7.nlargest(7, 'ë§¤ì¶œì•¡')
        
        # ê²°ê³¼ í¬ë§·íŒ…
        result = [{
            'id': str(row['id']),
            'category': row['ëŒ€ë¶„ë¥˜'],  # ëŒ€ë¶„ë¥˜
            'subcategory': row['ì†Œë¶„ë¥˜'],  # ì†Œë¶„ë¥˜
            'sales': float(row['ë§¤ì¶œì•¡']),
            'date': latest_date
        } for _, row in daily_top_7.iterrows()]
        
        return result
    except Exception as e:
        print(f"Error in get_daily_top_sales: {str(e)}")
        return []
        

@app.get("/api/inventory")
def get_inventory(sort: str = "asc", main: str = None, sub1: str = None, sub2: str = None):
    try:
        response = supabase.from_('product_inventory').select("""
            id, value,
            product_info (
                main, sub1, sub2, sub3
            )
        """).execute()

        df_inventory = pd.DataFrame(response.data)

        # âœ… `id` ê°’ì„ ìœ ì§€í•˜ê³  ë¬¸ìì—´ë¡œ ë³€í™˜ (í”„ë¡ íŠ¸ì™€ ì¼ê´€ë˜ê²Œ ë§¤í•‘)
        df_inventory["id"] = df_inventory["id"].astype(str)

        # âœ… `product_info` ì»¬ëŸ¼ì—ì„œ í•„ìš”í•œ ê°’ ì¶”ì¶œ
        df_inventory["main"] = df_inventory["product_info"].apply(lambda x: x.get("main", None) if isinstance(x, dict) else None)
        df_inventory["sub1"] = df_inventory["product_info"].apply(lambda x: x.get("sub1", None) if isinstance(x, dict) else None)
        df_inventory["sub2"] = df_inventory["product_info"].apply(lambda x: x.get("sub2", None) if isinstance(x, dict) else None)
        df_inventory["sub3"] = df_inventory["product_info"].apply(lambda x: x.get("sub3", None) if isinstance(x, dict) else None)

        # âœ… ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° (`product_info`ëŠ” ì›ë³¸ JSONì´ë¯€ë¡œ ì‚­ì œ)
        df_inventory = df_inventory.drop(columns=["product_info"])
        
        # âœ… í•„í„°ë§ ì ìš©
        if main:
            df_inventory = df_inventory[df_inventory["main"] == main]
        if sub1:
            df_inventory = df_inventory[df_inventory["sub1"] == sub1]
        if sub2:
            df_inventory = df_inventory[df_inventory["sub2"] == sub2]

        # âœ… ì¬ê³  ìˆ˜ëŸ‰(value) ê¸°ì¤€ ì •ë ¬
        df_inventory = df_inventory.sort_values(by=["value"], ascending=(sort == "asc"))

        return df_inventory.to_dict(orient="records")
    
    except Exception as e:
        print(f"âŒ Error fetching inventory: {e!s}")
        return {"error": str(e)}

# âœ… ì¹´í…Œê³ ë¦¬ í•„í„° ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/category_filters")
def get_category_filters(main: str = None, sub1: str = None, sub2: str = None):
    """
    ì„ íƒëœ main, sub1, sub2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ëŠ¥í•œ sub1, sub2, sub3 ëª©ë¡ ë°˜í™˜
    """
    try:
        response = supabase.from_('product_info').select("main, sub1, sub2, sub3").execute()
        df = pd.DataFrame(response.data)

        filters = {}

        if main and sub1 and sub2:
            filters["sub3"] = sorted(df[(df["main"] == main) & (df["sub1"] == sub1) & (df["sub2"] == sub2)]["sub3"].dropna().unique().tolist())
        elif main and sub1:
            filters["sub2"] = sorted(df[(df["main"] == main) & (df["sub1"] == sub1)]["sub2"].dropna().unique().tolist())
        elif main:
            filters["sub1"] = sorted(df[df["main"] == main]["sub1"].dropna().unique().tolist())
        else:
            filters["main"] = sorted(df["main"].dropna().unique().tolist())

        return {"status": "success", "filters": filters}

    except Exception as e:
        return {"error": str(e)}



# âœ… ìµœì†Œ ì¬ê³  ê¸°ì¤€(ROP) ê³„ì‚° (ì„œë²„ ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ ìˆ˜í–‰)
def compute_fixed_reorder_points():
    try:
        response = supabase.from_('monthly_sales').select("*").execute()
        df_sales = pd.DataFrame(response.data)

        if df_sales.empty:
            return {}

        # âœ… ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì›” í‰ê·  íŒë§¤ëŸ‰ ê³„ì‚°
        valid_dates = [col for col in df_sales.columns if re.match(r"\d{2}_m\d{2}", col)]
        df_sales["monthly_avg_sales"] = df_sales[valid_dates].mean(axis=1).fillna(0)

        # âœ… ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ì¼ í‰ê·  íŒë§¤ëŸ‰ ê³„ì‚°
        df_sales["daily_avg_sales"] = df_sales["monthly_avg_sales"] / 30

        # âœ… ìµœì†Œ ì¬ê³  ê¸°ì¤€(ROP) ê³„ì‚°: ì¼ í‰ê·  íŒë§¤ëŸ‰ì˜ 2ë°° + 10
        df_sales["reorder_point"] = (df_sales["daily_avg_sales"] * 2 + 25).fillna(25)

        # âœ… `id`ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€
        df_sales["id"] = df_sales["id"].astype(str)

        # âœ… ìµœì†Œ ì¬ê³  ê¸°ì¤€ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥
        reorder_points = df_sales.set_index("id")["reorder_point"].to_dict()

        return reorder_points

    except Exception as e:
        print(f"âŒ ìµœì†Œ ì¬ê³  ê¸°ì¤€ ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
        return {}

# âœ… ì„œë²„ ì‹¤í–‰ ì‹œ ìµœì´ˆ ê³„ì‚°í•˜ì—¬ ì €ì¥
FIXED_REORDER_POINTS = compute_fixed_reorder_points()

    
@app.get("/api/reorder_points")
def get_reorder_points(start: str, end: str):
    try:
        response = supabase.from_('monthly_sales').select("*").execute()
        df_sales = pd.DataFrame(response.data)

        if df_sales.empty:
            return {"error": "ğŸš¨ Supabaseì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        # âœ… ì„ íƒí•œ ê¸°ê°„ì˜ ì›”ë³„ íŒë§¤ëŸ‰ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        valid_dates = [col for col in df_sales.columns if re.match(r"\d{2}_m\d{2}", col)]
        selected_dates = [col for col in valid_dates if start <= col <= end]

        if not selected_dates:
            return {"error": "ğŸš¨ ì„ íƒí•œ ê¸°ê°„ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # âœ… ì„ íƒí•œ ê¸°ê°„ì— ëŒ€í•œ ì›”/ì¼ í‰ê·  íŒë§¤ëŸ‰ ê³„ì‚°
        df_sales["monthly_avg_sales"] = df_sales[selected_dates].mean(axis=1).fillna(0)
        df_sales["daily_avg_sales"] = df_sales["monthly_avg_sales"] / 30

        # âœ… ìµœì†Œ ì¬ê³  ê¸°ì¤€(ROP)ì€ ì„œë²„ ì‹œì‘ ì‹œ ê³„ì‚°ëœ ê°’ ì‚¬ìš©
        df_sales["reorder_point"] = df_sales["id"].map(lambda x: FIXED_REORDER_POINTS.get(str(x), 10))

        # âœ… IDë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ë¬¸ì œ ë°©ì§€
        df_sales["id"] = df_sales["id"].astype(str)

        # âœ… í•„ìš”í•œ ë°ì´í„°ë§Œ ë°˜í™˜
        reorder_data = df_sales[["id", "monthly_avg_sales", "daily_avg_sales", "reorder_point"]].to_dict(orient="records")

        return reorder_data

    except Exception as e:
        print(f"âŒ ROP ê°±ì‹  ì˜¤ë¥˜: {str(e)}")
        return {"error": str(e)}
    

active_connections = []
db_path = os.path.join(os.path.dirname(__file__), "../database/database.db")

def order_db():
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name='auto_orders';"
    )
    table_exists = cursor.fetchone()

    # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
    if not table_exists:
        cursor.execute(
            """CREATE TABLE auto_orders (
                id INTEGER PRIMARY KEY,
                value INTEGER,
                is_orderable BOOLEAN
            )"""
        )
        conn.commit()
        print("âœ… í…Œì´ë¸” 'auto_orders'ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

    conn.close()

order_db()

# âœ… ì£¼ë¬¸ ë°ì´í„° ëª¨ë¸
class OrderItem(BaseModel):
    id: int
    value: int
    is_orderable: bool

class OrderData(BaseModel):
    items: List[OrderItem]

# âœ… WebSocket í•¸ë“¤ëŸ¬ (í”„ë¡ íŠ¸ì—”ë“œì™€ ì‹¤ì‹œê°„ ì—°ê²°)
@app.websocket("/ws/auto_orders")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    active_connections.append(websocket)
    try:
        while True:
            await websocket.receive_text()  # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹  (í•„ìš” ì—†ìœ¼ë©´ ì œê±° ê°€ëŠ¥)
    except WebSocketDisconnect:
        active_connections.remove(websocket)

# âœ… ì£¼ë¬¸ ë°ì´í„° ì €ì¥ + WebSocketìœ¼ë¡œ í”„ë¡ íŠ¸ì— ì „ì†¡
@app.post("/api/auto_orders")
async def save_auto_order(order_data: OrderData):
    if not order_data.items:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤.")
    db_path = os.path.join(os.path.dirname(__file__), "../database/database.db")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    for item in order_data.items:
        cursor.execute(
            """INSERT INTO auto_orders (id, value, is_orderable)
               VALUES (?, ?, ?)
               ON CONFLICT(id) DO UPDATE SET value = ?, is_orderable = ?""",
            (item.id, item.value, item.is_orderable, item.value, item.is_orderable),
        )

    conn.commit()
    conn.close()

    # âœ… ì£¼ë¬¸ ì™„ë£Œ ì´ë²¤íŠ¸ë¥¼ WebSocketì„ í†µí•´ í”„ë¡ íŠ¸ì— ì „ì†¡
    order_info = {"id": item.id, "value": item.value, "status": "âœ… ì£¼ë¬¸ ì™„ë£Œ"}
    for connection in active_connections:
        await connection.send_json(order_info)  # í”„ë¡ íŠ¸ì—”ë“œì— JSON ë°ì´í„° ì „ì†¡

    return {"status": "success", "message": "ìë™ ì£¼ë¬¸ ì™„ë£Œ ë¦¬ìŠ¤íŠ¸ ì €ì¥ë¨"}

# main
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=False) 